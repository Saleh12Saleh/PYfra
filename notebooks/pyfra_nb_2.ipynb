{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7605c7e7",
   "metadata": {},
   "source": [
    "Notebook 2\n",
    "==============\n",
    "Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2ef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pyfra\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbff80a",
   "metadata": {},
   "source": [
    "# Data import & pulling\n",
    "\n",
    "We have imported the data and separated them into four different categories: characteristics,places,users,vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a06582",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_categories = {'characteristics': 'caracteristiques', 'places':'lieux', 'users':'usagers', 'vehicles':'vehicules'}\n",
    "data_categories = french_categories.keys()\n",
    "categories_dict = dict(zip(data_categories, [0,0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214e1cb1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Define the function that reads the raw data for the specified time range\n",
    "def read_csv_of_year(start_year, end_year, separators, name_separator='_'):\n",
    "    if len (separators)<4:\n",
    "        separators = [separators]*4\n",
    "        \n",
    "    df_dict = {}\n",
    "    for year in range(start_year,end_year+1):\n",
    "        this_year_str = str(year)\n",
    "        # Data Category\n",
    "        this_df_dict = {}        \n",
    "        for this_category, this_sep in zip(data_categories, separators):\n",
    "            # We need the French name of the category for the filename\n",
    "            this_french_category = french_categories[this_category]\n",
    "            this_file_path_and_name = '../data/'+this_year_str+'/' + this_french_category+name_separator+this_year_str+'.csv'\n",
    "            this_df_dict[this_category] = pd.read_csv(this_file_path_and_name, encoding='latin-1', sep=this_sep, low_memory=False)\n",
    "        df_dict[year] = this_df_dict\n",
    "    return df_dict\n",
    "\n",
    "# Import years\n",
    "df_dict = {}\n",
    "df_dict.update(read_csv_of_year(2005, 2008, separators=','))\n",
    "df_dict.update(read_csv_of_year(2009,2009, separators=['\\t', ',', ',', ',']))\n",
    "df_dict.update(read_csv_of_year(2010, 2016, separators=','))\n",
    "df_dict.update(read_csv_of_year(2017, 2018, separators=',', name_separator='-'))\n",
    "df_dict.update(read_csv_of_year(2019, 2021, separators=';', name_separator='-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc914028",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_category_dfs = {}\n",
    "for this_category in data_categories:\n",
    "    dict_of_category_dfs[this_category] = pd.concat([df_dict[year][this_category] for year in range(2005,2022)], ignore_index=True)\n",
    "\n",
    "characteristics = dict_of_category_dfs['characteristics']\n",
    "places = dict_of_category_dfs['places']\n",
    "users = dict_of_category_dfs['users']\n",
    "vehicles = dict_of_category_dfs['vehicles']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2fe5b3",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "We will perform some of the cleaning of the data on the individual datasets. Not all cleaning is possible before merging the datasets, so there will be a second round of cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977048c3",
   "metadata": {},
   "source": [
    "## Calculate the percentage of missing values for each dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdb939cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_percentage(df):\n",
    "  return df.isna().sum() *100 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8daa80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characteristics\n",
      " Num_Acc     0.000000\n",
      "an          0.000000\n",
      "mois        0.000000\n",
      "jour        0.000000\n",
      "hrmn        0.000000\n",
      "lum         0.000000\n",
      "agg         0.000000\n",
      "int         0.000000\n",
      "atm         0.006509\n",
      "col         0.001694\n",
      "com         0.000178\n",
      "adr        12.774581\n",
      "gps        57.198251\n",
      "lat        43.427300\n",
      "long       43.427656\n",
      "dep         0.000000\n",
      "dtype: float64 \n",
      "\n",
      "places\n",
      " Num_Acc     0.000000\n",
      "catr        0.000089\n",
      "voie        9.556239\n",
      "v1         56.690481\n",
      "v2         95.419907\n",
      "circ        0.140339\n",
      "nbv         0.243498\n",
      "pr         42.394463\n",
      "pr1        42.556646\n",
      "vosp        0.246173\n",
      "prof        0.173774\n",
      "plan        0.203375\n",
      "lartpc     19.511203\n",
      "larrout    10.060977\n",
      "surf        0.171545\n",
      "infra       0.482181\n",
      "situ        0.443128\n",
      "env1       15.027314\n",
      "vma        85.457720\n",
      "dtype: float64 \n",
      "\n",
      "users\n",
      " Num_Acc         0.000000\n",
      "place           4.906241\n",
      "catu            0.000000\n",
      "grav            0.000000\n",
      "sexe            0.000000\n",
      "trajet          0.019684\n",
      "secu           16.893474\n",
      "locp            2.245798\n",
      "actp            2.249823\n",
      "etatp           2.248069\n",
      "an_nais         0.218559\n",
      "num_veh         0.000000\n",
      "id_vehicule    85.359337\n",
      "secu1          85.359337\n",
      "secu2          85.359337\n",
      "secu3          85.359337\n",
      "dtype: float64 \n",
      "\n",
      "vehicles\n",
      " Num_Acc         0.000000\n",
      "senc            0.014204\n",
      "catv            0.000000\n",
      "occutc         14.456823\n",
      "obs             0.052535\n",
      "obsm            0.040629\n",
      "choc            0.020732\n",
      "manv            0.024440\n",
      "num_veh         0.000000\n",
      "id_vehicule    85.425312\n",
      "motor          85.425312\n",
      "dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for this_category, df in dict_of_category_dfs.items():\n",
    "    print(this_category+'\\n', na_percentage(df),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd537df",
   "metadata": {},
   "source": [
    "## Users Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d43c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grav\n",
    "users.grav.replace(to_replace=-1,value=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3b4c67",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Place\n",
    "\n",
    "users.place.value_counts()\n",
    "users.place.fillna(1,inplace=True) #replace is with mode\n",
    "users.place.replace(to_replace=-1,value=0,inplace=True) #-1 is unassigned , will put 0 unknown #Same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4047684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trajet\n",
    "\n",
    "users.trajet.replace(to_replace=-1,value=0,inplace=True) #-1 is unassigned , will put 0 unknown #Same result\n",
    "users.trajet.fillna(5,inplace=True) #replace is with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d81bcd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#locp\n",
    "\n",
    "users.locp.replace(to_replace=-1,value=0,inplace=True) #-1 is unassigned , will put 0 unknown #Same result\n",
    "users.locp.value_counts()\n",
    "users.locp.fillna(0,inplace=True) #replace is with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc021872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actp\n",
    "\n",
    "users.actp.replace(to_replace=['B'],value=0,inplace=True)#-1,B is unassigned , will put 0 unknown #Same result\n",
    "users.actp.replace(to_replace=' -1',value=0,inplace=True)\n",
    "users.actp.replace(to_replace=['A'],value=8,inplace=True) #A is coming in/out of vehicule , will put 8 instead (int)\n",
    "users.actp.fillna(0,inplace=True) #replace is with mode\n",
    "\n",
    "users.actp.replace(to_replace='0',value=0,inplace=True)\n",
    "users.actp.replace(to_replace='1',value=1,inplace=True)\n",
    "users.actp.replace(to_replace='2',value=2,inplace=True)\n",
    "users.actp.replace(to_replace='3',value=3,inplace=True)\n",
    "users.actp.replace(to_replace='4',value=4,inplace=True)\n",
    "users.actp.replace(to_replace='5',value=5,inplace=True)\n",
    "users.actp.replace(to_replace='6',value=6,inplace=True)\n",
    "users.actp.replace(to_replace='7',value=7,inplace=True)\n",
    "users.actp.replace(to_replace='8',value=8,inplace=True)\n",
    "users.actp.replace(to_replace='9',value=9,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24a6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#etatp\n",
    "\n",
    "users.etatp.replace(to_replace=-1,value=0,inplace=True) #-1, is unassigned , will put 0 unknown #Same result\n",
    "users.etatp.isna().sum() #119291\n",
    "users.etatp.value_counts() \n",
    "users.etatp.fillna(0,inplace=True) #replace is with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4527a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an_nais\n",
    "\n",
    "users.an_nais.isna().sum() #10080\n",
    "users.an_nais.value_counts() \n",
    "users.an_nais.fillna(1986.0,inplace=True)\n",
    "#replace is with mode #the first 5 values of value_counts are close to each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "507f343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sex \n",
    "users.sexe.replace(to_replace=-1,value=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4462a237",
   "metadata": {},
   "source": [
    "### Fixing incoherency of 'secu' Variable\n",
    "Safety equipment until 2018 was in 2 variables: existence and use.\n",
    "\n",
    "From 2019, it is the use with up to 3 possible equipments for the same user\n",
    "(especially for motorcyclists whose helmet and gloves are mandatory).\n",
    "\n",
    "#secu1\n",
    "The character information indicates the presence and use of the safety equipment:\n",
    "-1 - No information\n",
    "0 - No equipment\n",
    "1 - Belt\n",
    "2 - Helmet\n",
    "3 - Children device\n",
    "4 - Reflective vest\n",
    "5 - Airbag (2WD/3WD)\n",
    "6 - Gloves (2WD/3WD)\n",
    "7 - Gloves + Airbag (2WD/3WD)\n",
    "8 - Non-determinable\n",
    "9 - Other\n",
    "\n",
    "#secu2\n",
    "The character information indicates the presence and use of the safety equipment\n",
    "\n",
    "#secu3\n",
    "The character information indicates the presence and use of safety equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84bb0c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Security \n",
    "users.drop(columns='secu3',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8664735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searching for the exact index where the year 2019 starts to accuratly study secu factors\n",
    "X = users.loc[users['Num_Acc'].astype(str).str.startswith(\"2019\")].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e811cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#secu has some missing values for older years , must fill with mode before continuing\n",
    "\n",
    "users.secu[:X].fillna(value=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7b5f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['SecuA'] = ((users.secu - users.secu%10)/10) #Type of security Used\n",
    "users['SecuB']=   users.secu%10  # Was the security used or No\n",
    "\n",
    "#SecuA is not very important we will focus on secuB if the item was used or not to facilitate study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47999906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is unknown change to others 9 \n",
    "users.SecuA.replace(to_replace=0,value=9,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e370f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-No 3-UnDeterminable 0-Unknown , change all to 0 not used\n",
    "users.SecuB.replace(to_replace=3,value=0,inplace=True)\n",
    "users.SecuB.replace(to_replace=2,value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d2be3",
   "metadata": {},
   "source": [
    "For Secu1-secu2 \n",
    "We will gather all usage for security variable with 1 value {1} , and if there is no safety we will use {0} , No need to take multiple security parameters (secu2) we will noly take into consideration 1 security variable for comparibility with earlier years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32929ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.secu1.replace(to_replace=[2,3,4,5,6,7,8,9],value=1,inplace=True)\n",
    "users.secu1.replace(to_replace=[-1],value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ad26f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    335524\n",
       "0.0     31901\n",
       "Name: secu1, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.secu1.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39758376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1672237\n",
       "0.0     469958\n",
       "Name: SecuB, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.SecuB.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d7deb",
   "metadata": {},
   "source": [
    "Now both secu1 and secuB are same format we need to merge them into 1 column (for all years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b561eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louna\\AppData\\Local\\Temp\\ipykernel_148\\2256942316.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users['Security'][:X] = users.SecuB[:X]\n",
      "C:\\Users\\Louna\\AppData\\Local\\Temp\\ipykernel_148\\2256942316.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  users['Security'][X+1:] = users.secu1[X+1:]\n"
     ]
    }
   ],
   "source": [
    "#must add iloc\n",
    "users['Security']=0\n",
    "users['Security'][:X] = users.SecuB[:X]\n",
    "users['Security'][X+1:] = users.secu1[X+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aafb6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To drop unneeded columns\n",
    "#copy this to begining of df 3 before modeling for df\n",
    "#users = users.drop(columns=['secu','secu1','secu2','SecuA','SecuB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9550c4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Num_Acc         0.000000\n",
       "place           0.000000\n",
       "catu            0.000000\n",
       "grav            0.000000\n",
       "sexe            0.000000\n",
       "trajet          0.000000\n",
       "secu           14.640663\n",
       "locp            0.000000\n",
       "actp            0.000000\n",
       "etatp           0.000000\n",
       "an_nais         0.000000\n",
       "num_veh         0.000000\n",
       "id_vehicule    85.359337\n",
       "secu1          85.359337\n",
       "secu2          85.359337\n",
       "SecuA          14.640663\n",
       "SecuB          14.640663\n",
       "Security        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_percentage(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50b1e6",
   "metadata": {},
   "source": [
    "### Translating the variable names from French to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "502dc22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.rename(columns = {'catu' : 'User_category',\n",
    "                                'grav' : 'Severity' , #Severity of accident\n",
    "                                'sexe' : 'Sex' , #Sex of Driver\n",
    "                                'trajet' : 'Trajectory' , \n",
    "                                'locp' : 'LOCP' , #localisation of pedestrian\n",
    "                                'actp' : 'ACTP' , #action of pedestrian\n",
    "                                'etatp' : 'StateP' , #State of pedestrian during accident\n",
    "                                'an_nais' : 'YoB' , #Year of Birth\n",
    "                               })\n",
    "users.columns\n",
    "\n",
    "#change type to int\n",
    "users.place = users.place.astype(int)\n",
    "users.Trajectory = users.Trajectory.astype(int)\n",
    "users.LOCP = users.LOCP.astype(int)\n",
    "users.ACTP = users.ACTP.astype(int)\n",
    "users.StateP = users.StateP.astype(int)\n",
    "users.YoB = users.YoB.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62b73b",
   "metadata": {},
   "source": [
    "## Places Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907ded0",
   "metadata": {},
   "source": [
    "### Dropping unwanted columns , which are v1 , v2, vma, voie, env1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afd02abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droped 'Unnamed: 0','v1','v2','vma', because they contained no information.\n",
    "\n",
    "places = places.drop(['v1','v2','vma','voie','env1'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f44c32",
   "metadata": {},
   "source": [
    "### French to English Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b8493ab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num_Acc</th>\n",
       "      <th>Rd_Cat</th>\n",
       "      <th>Traf_Direct</th>\n",
       "      <th>Lanes</th>\n",
       "      <th>Landmark</th>\n",
       "      <th>Dist_to_Landmark</th>\n",
       "      <th>Add_Lanes</th>\n",
       "      <th>Rd_Prof</th>\n",
       "      <th>Rd_Plan</th>\n",
       "      <th>Gre_Verge</th>\n",
       "      <th>Rd_Width</th>\n",
       "      <th>Rd_Cond</th>\n",
       "      <th>Envinmt</th>\n",
       "      <th>Pos_Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200500000001</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200500000002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200500000003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200500000004</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200500000005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Num_Acc  Rd_Cat  Traf_Direct  Lanes Landmark Dist_to_Landmark  \\\n",
       "0  200500000001     3.0          2.0    2.0      1.0            430.0   \n",
       "1  200500000002     2.0          0.0    2.0      0.0              0.0   \n",
       "2  200500000003     2.0          0.0    0.0      0.0              0.0   \n",
       "3  200500000004     3.0          2.0    2.0      0.0              0.0   \n",
       "4  200500000005     3.0          2.0    2.0     24.0            630.0   \n",
       "\n",
       "   Add_Lanes  Rd_Prof  Rd_Plan Gre_Verge Rd_Width  Rd_Cond  Envinmt  Pos_Acc  \n",
       "0        0.0      1.0      1.0         0       63      1.0      0.0      1.0  \n",
       "1        1.0      1.0      1.0         0      100      1.0      0.0      5.0  \n",
       "2        1.0      1.0      1.0         0        0      2.0      0.0      5.0  \n",
       "3        0.0      1.0      1.0         0        0      1.0      0.0      1.0  \n",
       "4        0.0      1.0      3.0         0       59      2.0      0.0      3.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change french names against english names.\n",
    "\n",
    "places = places.rename(columns = {'catr' : 'Rd_Cat', 'circ' : 'Traf_Direct' , 'nbv' : 'Lanes' ,\n",
    "                           'pr' : 'Landmark' , 'pr1' : 'Dist_to_Landmark', 'vosp' : 'Add_Lanes', 'prof' : 'Rd_Prof' ,\n",
    "                          'plan' : 'Rd_Plan' , 'lartpc' : 'Gre_Verge' , 'larrout' : 'Rd_Width', 'surf' : 'Rd_Cond',\n",
    "                          'infra' : 'Envinmt' , 'situ' : 'Pos_Acc'})\n",
    "places.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e443cb",
   "metadata": {},
   "source": [
    "### Changing Nans with Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a36f6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no value = 0 assigned to information in the places data set. \n",
    "# Zeros are used in the cleaned data set as a feature to identify original Nans\n",
    "# and to keep the data set with as much information as possible.\n",
    "\n",
    "places = places.fillna({'Rd_Cat':0, 'Traf_Direct': 0, 'Lanes':0, 'Add_Lanes':0, 'Rd_Prof':0,'Rd_Plan':0,\n",
    "                        'Rd_Cond':0, 'Envinmt':0, 'Pos_Acc':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6509a0c",
   "metadata": {},
   "source": [
    "### Changing needed \"object\" Variables to \"int\" Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4897a18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num_Acc             0\n",
      "Rd_Cat              0\n",
      "Traf_Direct         0\n",
      "Lanes               0\n",
      "Landmark            0\n",
      "Dist_to_Landmark    0\n",
      "Add_Lanes           0\n",
      "Rd_Prof             0\n",
      "Rd_Plan             0\n",
      "Gre_Verge           0\n",
      "Rd_Width            0\n",
      "Rd_Cond             0\n",
      "Envinmt             0\n",
      "Pos_Acc             0\n",
      "dtype: int64\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1121571 entries, 0 to 1121570\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count    Dtype\n",
      "---  ------            --------------    -----\n",
      " 0   Num_Acc           1121571 non-null  int64\n",
      " 1   Rd_Cat            1121571 non-null  int32\n",
      " 2   Traf_Direct       1121571 non-null  int32\n",
      " 3   Lanes             1121571 non-null  int32\n",
      " 4   Landmark          1121571 non-null  int32\n",
      " 5   Dist_to_Landmark  1121571 non-null  int32\n",
      " 6   Add_Lanes         1121571 non-null  int32\n",
      " 7   Rd_Prof           1121571 non-null  int32\n",
      " 8   Rd_Plan           1121571 non-null  int32\n",
      " 9   Gre_Verge         1121571 non-null  int32\n",
      " 10  Rd_Width          1121571 non-null  int32\n",
      " 11  Rd_Cond           1121571 non-null  int32\n",
      " 12  Envinmt           1121571 non-null  int32\n",
      " 13  Pos_Acc           1121571 non-null  int32\n",
      "dtypes: int32(13), int64(1)\n",
      "memory usage: 64.2 MB\n",
      "None\n",
      "\n",
      "(1121571, 14)\n"
     ]
    }
   ],
   "source": [
    "# Convert 'object' Variables to 'float' Variables\n",
    "\n",
    "object_list = ['Landmark', 'Dist_to_Landmark', 'Gre_Verge', 'Rd_Width']\n",
    "\n",
    "places[object_list] = places[object_list].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "\n",
    "# Replace empty cells with 'Nans'\n",
    "\n",
    "places.replace('', np.nan).copy()\n",
    "\n",
    "# Fill 'Nans' with 0\n",
    "\n",
    "places = places.fillna({'Landmark':0, 'Dist_to_Landmark': 0, 'Gre_Verge':0, 'Rd_Width':0})\n",
    "\n",
    "# Convert 'float' Variables to 'int' Variables\n",
    "\n",
    "float_list = ['Rd_Cat', 'Traf_Direct', 'Lanes', 'Landmark','Dist_to_Landmark', 'Add_Lanes', 'Rd_Prof', 'Rd_Plan',\n",
    "              'Gre_Verge', 'Rd_Width', 'Rd_Cond', 'Envinmt','Pos_Acc']\n",
    "\n",
    "places[float_list] = places[float_list].astype(int, errors = 'raise')\n",
    "\n",
    "print(places.isna().sum())\n",
    "print()\n",
    "print(places.info())\n",
    "print()\n",
    "print(places.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b5f2f",
   "metadata": {},
   "source": [
    "## Characteristics Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95504124",
   "metadata": {},
   "source": [
    "### Translating the variable names from French to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0695a823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation of the variable nacmes from French to English, also improving the names so that it becomes clearer, what they are about\n",
    "characteristics.rename(columns={'an': 'year', 'mois':'month', 'jour': 'day', 'hrmn':'hhmm', \n",
    "                                'lum': 'daylight', 'agg': 'built-up_area', 'int':'intersection_category', 'atm': 'atmospheric_conditions',\n",
    "                                'col': 'collision_category', 'com': 'municipality', 'adr':'adress', 'gps': 'gps_origin', 'lat': 'latitude',\n",
    "                                'long': 'longitude', 'dep': 'department'}, inplace=True)\n",
    "\n",
    "# Change the values for 'built-up_area' to make it more understandable, 1 means the accident happened in a built-up area and 0 means happened elsewhere. \n",
    "characteristics['built-up_area'].replace({1:0, 2:1}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b3968",
   "metadata": {},
   "source": [
    "### Fixing incoherent format of year variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97e70b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       87026\n",
       "7       83850\n",
       "6       82993\n",
       "8       76767\n",
       "9       74409\n",
       "10      69379\n",
       "11      66974\n",
       "12      62250\n",
       "17      60701\n",
       "14      59854\n",
       "16      59432\n",
       "2019    58840\n",
       "15      58654\n",
       "13      58397\n",
       "18      57783\n",
       "2021    56518\n",
       "2020    47744\n",
       "Name: year, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characteristics['year'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b13c2b",
   "metadata": {},
   "source": [
    "The year format is inconsistent. Until 2018, the year was relative to the year 2000, e.g. \"5\" for 2005. This changed, however, in 2019 which was labeled as 2019.\n",
    "We will change the year format to YYYY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "594fb1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics['year'].replace({5:2005, 6:2006, 7:2007, 8:2008, 9:2009, 10:2010, 11:2011,\n",
    "                                                         12:2012, 13:2013, 14:2014, 15:2015, 16:2016, 17:2017, 18:2018}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2e10a",
   "metadata": {},
   "source": [
    "### Fix inconsistent time format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab3a02",
   "metadata": {},
   "source": [
    "The time format inconsistent, sometimes it is hhmm, and sometimes hh:mm. We will therefore remove any \":\" from the column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9410433",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#remove ':' from hhmm\n",
    "characteristics['hhmm'] = characteristics['hhmm'].apply(lambda s: int(str(s).replace(':','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d0770",
   "metadata": {},
   "source": [
    "### Get weekday and weekend feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98674398",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics['date'] = pd.to_datetime({'year':characteristics['year'],\n",
    "                                                                 'month':dict_of_category_dfs['characteristics']['month'],\n",
    "                                                                 'day':dict_of_category_dfs['characteristics']['day']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fa73b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New variable: weekday, integer from 0 to 6 representing the weekdays from monday to sunday.\n",
    "characteristics['day_of_week'] = dict_of_category_dfs['characteristics']['date'].apply(lambda x: x.day_of_week)\n",
    "\n",
    "# New binary variable: is_weekend, 0 for monday to friday and 1 for saturday and sunday\n",
    "characteristics['is_weekend'] = (dict_of_category_dfs['characteristics']['day_of_week'] > 4).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aaefa1",
   "metadata": {},
   "source": [
    "### Remove trailing zeroes from Department variable\n",
    "The Department codes are followed by a zero for the years 2005--2018, which has no practical use for us. We will therefore eliminate these trailing zeroes.\n",
    "Also, since 2019 all the data is saved as strings. We will convert everything to strings, as this is nominal data, we will not make any calculations with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "669a1d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def department_converter(dep):\n",
    "    # Takes in a department code as int and returns a string\n",
    "    # e.g. 750 will be '75' for Paris\n",
    "    # and 201 will be '2B'\n",
    "    if dep == 201:\n",
    "        return '2A'\n",
    "    elif dep == 202:\n",
    "        return '2B'\n",
    "    elif dep>970:\n",
    "        return str(dep)\n",
    "    else:\n",
    "        return str(dep).rstrip('0')\n",
    "\n",
    "characteristics.loc[(np.less(characteristics['year'],2019)),'department'] = \\\n",
    "    characteristics[(np.less(characteristics['year'],2019))]['department'].apply(department_converter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b388c39",
   "metadata": {},
   "source": [
    "### Remove leading zeros from department code\n",
    "The dataset from 2021 contains leading zeroes for the department codes 1 to 9. These have to be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45b23113",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics['department'] = characteristics['department'].apply(lambda code: code.lstrip('0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30780e",
   "metadata": {},
   "source": [
    "### Fill missing values in atmospheric conditions variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b991b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics['atmospheric_conditions'] = characteristics['atmospheric_conditions'].fillna(\n",
    "    characteristics['atmospheric_conditions'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121e6b2f",
   "metadata": {},
   "source": [
    "### Fill missing values in collision category variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "513d9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "characteristics['collision_category'] = characteristics['collision_category'].fillna(\n",
    "    characteristics['collision_category'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb856d04",
   "metadata": {},
   "source": [
    "## Vehicles dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445c7f8",
   "metadata": {},
   "source": [
    "### Translating the variable names from French to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e840bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Num_Acc', 'direction', 'cat_veh', 'num_occupants', 'obstacle',\n",
       "       'obstacle_movable', 'initial_point', 'principal_maneuver', 'num_veh',\n",
       "       'id_veh', 'motor_veh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles = vehicles.rename(columns = {'id_vehicule' : 'id_veh' , 'num_veh' : 'num_veh' ,\n",
    "                           'senc' : 'direction' , 'catv' : 'cat_veh', 'obs' : 'obstacle', 'obsm' : 'obstacle_movable' ,\n",
    "                          'choc' : 'initial_point' , 'manv' : 'principal_maneuver' , 'motor' : 'motor_veh', 'occutc' : 'num_occupants'})\n",
    "vehicles.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f83c38d",
   "metadata": {},
   "source": [
    "### Check of the variables with the most missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b030c",
   "metadata": {},
   "source": [
    "Variable num_occupants is representing amount of passangers being victims of an accident when they used public transport system. Missing values are caused by not recording value 0 and keeping the cell empty. For this reason we decided to replace the missing values by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9990ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles[\"num_occupants\"] = vehicles[\"num_occupants\"].fillna(0)\n",
    "vehicles['num_occupants'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74c882a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0      1901517\n",
       "1.0         7079\n",
       "2.0         1033\n",
       "10.0         654\n",
       "3.0          544\n",
       "          ...   \n",
       "97.0           1\n",
       "73.0           1\n",
       "102.0          1\n",
       "82.0           1\n",
       "78.0           1\n",
       "Name: num_occupants, Length: 124, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles['num_occupants'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e905c",
   "metadata": {},
   "source": [
    "The variable motor_veh represents the type of the motorisation of the vehicle. There are 85 % missing values in this column. Some of the values of this variable don't specificate an exact type but are tracked as unspecified, unknown, or other. We have decided to drop this variable as it doesn't have any significant influence on the target variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90c0c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicles = vehicles.drop(columns=['motor_veh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b746d749",
   "metadata": {},
   "source": [
    "8 Variables have <= 1% missing information, so for those it should be fine to set the missing information just to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fa5d592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Num_Acc                     0\n",
       "direction                   0\n",
       "cat_veh                     0\n",
       "num_occupants               0\n",
       "obstacle                    0\n",
       "obstacle_movable            0\n",
       "initial_point               0\n",
       "principal_maneuver          0\n",
       "num_veh                     0\n",
       "id_veh                1635811\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles[['Num_Acc', 'direction', 'cat_veh', 'obstacle', 'obstacle_movable', 'initial_point', 'principal_maneuver']] = vehicles[['Num_Acc', 'direction', 'cat_veh', 'obstacle', 'obstacle_movable', 'initial_point', 'principal_maneuver']].fillna(0)\n",
    "vehicles.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d865905",
   "metadata": {},
   "source": [
    "# Merge all datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed50826",
   "metadata": {},
   "source": [
    "## Ensure Correct Attribution of Users to Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c106f340",
   "metadata": {},
   "outputs": [],
   "source": [
    "users['id_vehicule'].fillna(users['num_veh'], inplace=True)\n",
    "users.drop(columns=['num_veh'], inplace=True)\n",
    "users.rename(columns={'id_vehicule': 'id_veh'}, inplace=True)\n",
    "users.set_index(['Num_Acc', 'id_veh'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e420e46e",
   "metadata": {},
   "source": [
    "## Left Join for further investigations\n",
    "We will continue working with the left join of the data, as the missing lines miss the most important variables anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "161795e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place                      0.000000\n",
      "User_category              0.000000\n",
      "Severity                   0.000000\n",
      "Sex                        0.000000\n",
      "Trajectory                 0.000000\n",
      "secu                      14.640663\n",
      "LOCP                       0.000000\n",
      "ACTP                       0.000000\n",
      "StateP                     0.000000\n",
      "YoB                        0.000000\n",
      "secu1                     85.359337\n",
      "secu2                     85.359337\n",
      "SecuA                     14.640663\n",
      "SecuB                     14.640663\n",
      "Security                   0.000000\n",
      "Num_Acc                    0.000000\n",
      "direction                 85.359337\n",
      "cat_veh                   85.359337\n",
      "num_occupants             85.359337\n",
      "obstacle                  85.359337\n",
      "obstacle_movable          85.359337\n",
      "initial_point             85.359337\n",
      "principal_maneuver        85.359337\n",
      "num_veh                   85.359337\n",
      "id_veh                     0.000000\n",
      "year                       0.000000\n",
      "month                      0.000000\n",
      "day                        0.000000\n",
      "hhmm                       0.000000\n",
      "daylight                   0.000000\n",
      "built-up_area              0.000000\n",
      "intersection_category      0.000000\n",
      "atmospheric_conditions     0.000000\n",
      "collision_category         0.000000\n",
      "municipality               0.000239\n",
      "adress                    13.695579\n",
      "gps_origin                56.303823\n",
      "latitude                  42.472167\n",
      "longitude                 42.472566\n",
      "department                 0.000000\n",
      "date                       0.000000\n",
      "day_of_week                0.000000\n",
      "is_weekend                 0.000000\n",
      "Rd_Cat                     0.000000\n",
      "Traf_Direct                0.000000\n",
      "Lanes                      0.000000\n",
      "Landmark                   0.000000\n",
      "Dist_to_Landmark           0.000000\n",
      "Add_Lanes                  0.000000\n",
      "Rd_Prof                    0.000000\n",
      "Rd_Plan                    0.000000\n",
      "Gre_Verge                  0.000000\n",
      "Rd_Width                   0.000000\n",
      "Rd_Cond                    0.000000\n",
      "Envinmt                    0.000000\n",
      "Pos_Acc                    0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = users.merge(vehicles, how='left', left_index=True, right_on=['Num_Acc', 'id_veh']) \\\n",
    "     .merge(characteristics, how='left', on='Num_Acc') \\\n",
    "     .merge(places, how='left', on='Num_Acc')\n",
    "\n",
    "print(na_percentage(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58797f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['year'] - df['YoB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8149f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "del characteristics, places, vehicles, users, dict_of_category_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43721b5",
   "metadata": {},
   "source": [
    "## One-Hot Encoding of Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d589e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df.sample(frac=0.1, random_state=23),\n",
    "       columns=['daylight', 'built-up_area', 'intersection_category', \n",
    "              'atmospheric_conditions', 'collision_category', 'department',\n",
    "              'Rd_Cat', 'Traf_Direct', 'Add_Lanes', 'Rd_Prof', 'Rd_Plan', \n",
    "              'Rd_Cond', 'Envinmt', 'Pos_Acc', 'place', \n",
    "              'User_category', 'Sex', 'Trajectory', 'LOCP', 'ACTP', \n",
    "              'StateP', 'direction', \n",
    "              'cat_veh', 'obstacle', 'obstacle_movable', 'initial_point', 'principal_maneuver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9739894e",
   "metadata": {},
   "source": [
    "# Export DataFrame to Pickle \n",
    "This step is necessary to be able to work with the data in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dc22feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('../data/df.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad340bda",
   "metadata": {},
   "source": [
    "The pickle file is too big to track on github, we will therefore create a second file which contains the output of the describe-method as well as the number of nans for each column and the dtypes of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d5e28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_info = pyfra.df_testing_info(df)\n",
    "df_check_info.to_csv('../data/df_check_info.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-LanguageId",
   "formats": "ipynb,py:light",
   "main_language": "python",
   "notebook_metadata_filter": "-kernelspec"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
